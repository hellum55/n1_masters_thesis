{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d55b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read csv file\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('C:/Users/Christian/Desktop/N1_data/N1GO kabelskabe.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bf1716",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"C:/Users/Christian/Desktop/N1_data/sampled_dataset.csv\", sep=',')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2817bc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[~df[\"ImageName\"].isin(df1[\"ImageName\"])]\n",
    "filtered_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbb26be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new column named ai_acc_series. If ValidatedSeries is equal to AISeries ai_acc_series = 1 else 0\n",
    "filtered_df['ai_acc_series'] = filtered_df.apply(lambda x: 1 if x['ValidatedSeries'] == x['AISeries'] else 0, axis=1)\n",
    "filtered_df['ai_acc_type'] = filtered_df.apply(lambda x: 1 if x['ValidatedType'] == x['AIType'] else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdaad28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove NaNs from ValidatedSeries and ValidatedType columns\n",
    "filtered_df = filtered_df[filtered_df['ValidatedSeries'].notna()]\n",
    "filtered_df = filtered_df[filtered_df['ValidatedType'].notna()]\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6314b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep only rows where \"ai_acc_series\" and \"ai_acc_type\" is both 1\n",
    "filtered_df = filtered_df[(filtered_df[\"ai_acc_series\"] == 1) & (filtered_df[\"ai_acc_type\"] == 1)]\n",
    "#filtered_df = filtered_df[(filtered_df[\"ai_acc_type\"] == 1)]\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85bf9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep only rows where ValidatedConditionId is 1.0 or 2.0\n",
    "filtered_df = filtered_df[(filtered_df[\"ValidatedConditionId\"] == 1.0) | (filtered_df[\"ValidatedConditionId\"] == 2.0)]\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e2217e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#in column AISeries and AIType replace \",\" with \".\"\n",
    "filtered_df['AISeriesProbability'] = filtered_df['AISeriesProbability'].str.replace(',', '.')\n",
    "filtered_df['AITypeProbability'] = filtered_df['AITypeProbability'].str.replace(',', '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a634ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep only rows where AISeriesProbability and AITypeProbability is above 0.9\n",
    "filtered_df = filtered_df[(filtered_df[\"AISeriesProbability\"].astype(float) > 0.9) & (filtered_df[\"AITypeProbability\"].astype(float) > 0.9)]\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff392a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a pivot table showing the distribution of ValidatedType and ValidatedConditionId\n",
    "filtered_df.pivot_table(index='ValidatedType', columns='ValidatedConditionId', aggfunc='size', fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0409e8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = pd.read_csv(\"C:/Users/Christian/Desktop/N1_data/clean_data.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a1ae5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the sampling requirements\n",
    "sampling_requirements = {\n",
    "    \"BC\": 10, \"BC K.M.skab\": 40, \"CP1\": 100, \"CP3\": 70, \"CP4\": 60, \"CP6\": 50,\n",
    "    \"KSE09\": 55, \"KSE12\": 60, \"KSE15\": 50, \"KSE18\": 40, \"KSE21\": 50, \"KSE27\": 50,\n",
    "    \"Kombimodul 2M\": 60, \"Kombimodul 3M\": 10, \"MEL1\": 24, \"MEL2\": 61, \"MEL3\": 50,\n",
    "    \"MEL4\": 3, \"PK20\": 60, \"NU\": 100, \"PK35\": 55, \"PK48\": 50, \"SC\": 70\n",
    "}\n",
    "\n",
    "# Create an empty DataFrame to store the sampled data\n",
    "sampled_df = pd.DataFrame()\n",
    "\n",
    "# Perform random sampling for each ValidatedType\n",
    "for validated_type, sample_size in sampling_requirements.items():\n",
    "    sampled_data = filtered_df[filtered_df[\"ValidatedType\"] == validated_type].sample(n=sample_size, random_state=42)\n",
    "    sampled_df = pd.concat([sampled_df, sampled_data])\n",
    "\n",
    "# Reset the index of the resulting DataFrame\n",
    "sampled_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the sampled DataFrame\n",
    "sampled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98c5814",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99eb626d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the sampled_df to a csv file called sampled_dataset2.csv\n",
    "sampled_df.to_csv(\"C:/Users/Christian/Desktop/N1_data/sampled_dataset2.csv\", sep=',', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
